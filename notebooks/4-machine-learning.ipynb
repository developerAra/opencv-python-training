{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2000)\n",
      "(2500, 400)\n",
      "(2500, 400)\n"
     ]
    }
   ],
   "source": [
    "mnist = cv2.imread('../datasets/digits.png', 0)\n",
    "print(mnist.shape)\n",
    "images = [np.hsplit(row, 100) for row in np.vsplit(mnist, 50)]\n",
    "images = np.array(images, dtype=np.float32)\n",
    "\n",
    "train_features = images[:, :50].reshape(-1, (20 * 20))\n",
    "test_features = images[:, 50:100].reshape(-1, (20 * 20))\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "#ADDED FOR MEAN NORMALIZATION\n",
    "train_features -= np.mean(train_features, axis = 0)\n",
    "test_features -= np.mean(train_features, axis = 0)\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "ret, result, neighbors, dist = knn.findNearest(test_features, 3)\n",
    "\n",
    "#check if the results are correct\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "#convert bool to int\n",
    "matches = matches.astype(np.int)\n",
    "\n",
    "#count the correct predictions\n",
    "correct = np.count_nonzero(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.24\n"
     ]
    }
   ],
   "source": [
    "#compute the accuracy\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FASHION MNIST\n",
    "fnist = cv2.imread('../datasets/fashion.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 840)\n"
     ]
    }
   ],
   "source": [
    "print(fnist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [np.hsplit(row, 30) for row in np.vsplit(fnist, 30)]\n",
    "\n",
    "images = np.array(images, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAD6RJREFUeJzt3V2sVeWdx/HfX0QE6gugCCKC5UXHcGGR4GDLBGOozljjS4KpV4wzGUpSkzHxYow3NZk0NhPbca6aYEpKk9a2UTuYppm20UnxQo1gDNIybbHBcgRBoMibyNt/Ls6iOeJZ/2ez39bG//eTkHPO/u9n7Yd19u/stfez1vOYuwtAPhc03QEAzSD8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSurCfD2ZmnE4I9Ji7Wyv36+iV38zuNLPfm9k2M3usk20B6C9r99x+Mxsj6Q+SlksakvSGpAfd/XdBG175gR7rxyv/Yknb3P1P7n5c0o8l3dPB9gD0USfhnyFpx4ifh6rbPsHMVpnZRjPb2MFjAeiyTj7wG+3Q4lOH9e6+RtIaicN+YJB08so/JGnmiJ+vkbSzs+4A6JdOwv+GpHlmdp2ZXSTpq5Je7E63APRa24f97n7SzB6W9EtJYyStdfffdq1nAHqq7aG+th6M9/xAz/XlJB8A5y/CDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmp7iW5JMrPtkg5JOiXppLsv6kanAPReR+Gv3Obue7uwHQB9xGE/kFSn4XdJvzKzTWa2qhsdAtAfnR72f9Hdd5rZVEm/NrP/c/cNI+9Q/VHgDwMwYMzdu7MhsyckHXb3p4L7dOfBANRyd2vlfm0f9pvZRDO75Mz3kr4saUu72wPQX50c9l8l6WdmdmY7P3L3/+lKrwD0XNcO+1t6MA77gZ7r+WE/gPMb4QeSIvxAUoQfSIrwA0kRfiCpblzVh4LqXIi2lYZjo+1fcEH89/306dMdPXbJ2LFja2sPPfRQ2PaZZ54J6/0cpv4s4pUfSIrwA0kRfiApwg8kRfiBpAg/kBThB5JinL8Pej0eHW3/1KlTHW173LhxYX3q1Klh/ZJLLqmt3XfffWHbG2+8Maw/8sgjYT06/+HCC+Onfun8h073680331xbGxoaCtvu3r27o8c+g1d+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iKqbs/A8aPH19bmzNnTkfbXr58eVjfsWNHWI/G+RcuXBi2XbFiRVifNm1aWG/S7bffHtafeqp2YSs9/fTTYdt169aFdabuBhAi/EBShB9IivADSRF+ICnCDyRF+IGkitfzm9laSV+RtMfdF1S3TZb0E0mzJW2X9IC7/6V33URk9erVtbXrr78+bPvyyy+H9YMHD4b1efPmhfXIa6+9Ftbnz58f1kvnqLzyyiu1tSNHjoRt9+zZE9ZL1/vPnTs3rEfnZpT+393Syiv/9yXdedZtj0l6yd3nSXqp+hnAeaQYfnffIGn/WTffI+nMaUbrJN3b5X4B6LF23/Nf5e67JKn6Gs/lBGDg9HwOPzNbJWlVrx8HwLlp95V/t5lNl6Tqa+2nI+6+xt0XufuiNh8LQA+0G/4XJa2svl8paX13ugOgX4rhN7NnJb0q6XozGzKzf5b0LUnLzeyPkpZXPwM4j/T9ev5O1pKP9Hqd+V6aMWNGWF+8eHFYnzx5cm3t/fffD9tee+21YX3KlClhvTR//eWXX15bmzlzZti2dI5B9P+WynPzR0rnAZT6Hs1jIMXP9dI5BnfccUdY53p+ACHCDyRF+IGkCD+QFOEHkiL8QFJM3d2isWPH1taWLFkSti0tNV1a5ro07LR3797aWmk4bNKkSWG9pLSE90UXXVRbO3bsWNh24sSJYf3EiRNhPdpv06dPD9uWLoUuDS2fPHkyrEf7LdpnknTLLbeEdYb6AIQIP5AU4QeSIvxAUoQfSIrwA0kRfiCpnk/jdS5K47rR5aGlMd/oUmKpfPlndAnnrFmzwralcfqdO3eG9QMHDoT16ByE0j7tVGk8O6qXxrM7nV576dKltbXS76y09Pjx48fD+hVXXBHWo+dbqW30XD6X83Z45QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpPo6zj9u3LhwfPXuu+8O27/11lu1tdI4f2mq5dL12dFYe6ntNddcE9ZL19yXxpxL48KR6ByBVpTOj4imqC6N83/wwQdhvXTN/a233lpb27//7LVnP+mGG24I66Xfeen5uG/fvtpaaZ9edtlltbVDhw6FbUfilR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiqO85vZWklfkbTH3RdUtz0h6V8knRmIfdzdf1Ha1oQJE7Rw4cLaemlsNRrPjuaul6QPP/wwrF955ZVhPVI6h6A0Dl+a+/66664L65s3b66tlZbQjsaMWzFmzJi22x49ejSsl5a5Xr58eViPxvK3bNkSti0tbV4aTx8aGgrr0ZoFpSW4o3MMun09//cl3TnK7f/p7jdV/4rBBzBYiuF39w2S4tOhAJx3OnnP/7CZbTaztWbW2ZpPAPqu3fB/V9IcSTdJ2iXp23V3NLNVZrbRzDZ+/PHHbT4cgG5rK/zuvtvdT7n7aUnPSFoc3HeNuy9y90WlD7YA9E9b4TezkUuc3icp/ugUwMBpZajvWUnLJF1hZkOSviFpmZndJMklbZf0tR72EUAP2LmMC3b8YGYezTm+YsWKsH10vf+SJUvCtqVx/nfeeSesf/TRR7W10tuZiy++OKyXrqkvjXdH7d99992wben/XTJhwoSwHv2+S+cglNYcKI2lv/fee7W16PcpxWtESNKkSfFn3KXnRPQ7LZ0Xsnr16trasWPHdPr06XiRigpn+AFJEX4gKcIPJEX4gaQIP5AU4QeS6vtQX1SfO3du2D5akvngwYNh20cffTSs33XXXWE9uuR3/PjxYdvSZa+lobzSMthR+9Ip1aWhwMOHD4f10vaj51cnlwNL8bTgkjRlypTaWul3Vhp+LU3NXRJNS17adjQkvm/fPp04cYKhPgD1CD+QFOEHkiL8QFKEH0iK8ANJEX4gqYEa5y9ZtmxZbW3OnDlh2/Xr14f1aMlkSZo2bVptrTRmfPXVV4f10jh+6Xe0c+fOtrddWg66tBR1afvRWHzpHIFLL700rEfj+FJ8OXGp36V6ab8cOXIkrEfPt9mzZ4dto2m/d+zYoWPHjjHOD6Ae4QeSIvxAUoQfSIrwA0kRfiApwg8k1fdx/uga7tJUzpHbbrstrEfj9JK0dOnSsL5hw4baWmmc/8CBA2H9+PHjYb00RfWCBQtqa6Wx9NI18aX6rFmzwno0Vl+ax2DTpk1hvTQWH10XXzpHoJSL0mOXpmufP39+ba10XsiTTz5ZW9u6dauOHDnCOD+AeoQfSIrwA0kRfiApwg8kRfiBpAg/kFRxnN/MZkr6gaRpkk5LWuPu/2VmkyX9RNJsSdslPeDufylsq38nFZyj0hzyM2fOrK0tXrw4bPvqq6+G9fvvvz+sP/fcc2E9mstg8+bNYdvSHPGlcxBK509Ey2xPnjw5bLtt27awXhoPj9YcKPW7ZP/+/WH96NGjYT2at780F0CJu3dtnP+kpEfd/W8k/a2kr5vZjZIek/SSu8+T9FL1M4DzRDH87r7L3d+svj8kaaukGZLukbSuuts6Sff2qpMAuu+c3vOb2WxJX5D0uqSr3H2XNPwHQtLUbncOQO/EE7iNYGafk/S8pEfc/WA0P9pZ7VZJWtVe9wD0Skuv/GY2VsPB/6G7v1DdvNvMplf16ZJGXUXT3de4+yJ3X9SNDgPojmL4bfgl/nuStrr7d0aUXpS0svp+paR4elwAA6WVob4vSXpF0tsaHuqTpMc1/L7/p5KulfRnSSvcPRz/GOShPuCzotWhvvNq3n4AZd0c5wfwGUT4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKoYfjObaWb/a2Zbzey3Zvav1e1PmNl7ZvZW9e8fet9dAN1i7h7fwWy6pOnu/qaZXSJpk6R7JT0g6bC7P9Xyg5nFDwagY+5urdzvwhY2tEvSrur7Q2a2VdKMzroHoGnn9J7fzGZL+oKk16ubHjazzWa21swm1bRZZWYbzWxjRz0F0FXFw/6/3tHsc5J+I+mb7v6CmV0laa8kl/TvGn5r8E+FbXDYD/RYq4f9LYXfzMZK+rmkX7r7d0apz5b0c3dfUNgO4Qd6rNXwt/Jpv0n6nqStI4NffRB4xn2StpxrJwE0p5VP+78k6RVJb0s6Xd38uKQHJd2k4cP+7ZK+Vn04GG2LV36gx7p62N8thB/ova4d9gP4bCL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kVZzAs8v2Snp3xM9XVLcNokHt26D2S6Jv7epm32a1ese+Xs//qQc32+juixrrQGBQ+zao/ZLoW7ua6huH/UBShB9Iqunwr2n48SOD2rdB7ZdE39rVSN8afc8PoDlNv/IDaEgj4TezO83s92a2zcwea6IPdcxsu5m9Xa083OgSY9UyaHvMbMuI2yab2a/N7I/V11GXSWuobwOxcnOwsnSj+27QVrzu+2G/mY2R9AdJyyUNSXpD0oPu/ru+dqSGmW2XtMjdGx8TNrO/k3RY0g/OrIZkZv8hab+7f6v6wznJ3f9tQPr2hM5x5eYe9a1uZel/VIP7rpsrXndDE6/8iyVtc/c/uftxST+WdE8D/Rh47r5B0v6zbr5H0rrq+3UafvL0XU3fBoK773L3N6vvD0k6s7J0o/su6Fcjmgj/DEk7Rvw8pMFa8tsl/crMNpnZqqY7M4qrzqyMVH2d2nB/zlZcubmfzlpZemD2XTsrXndbE+EfbTWRQRpy+KK7L5T095K+Xh3eojXflTRHw8u47ZL07SY7U60s/bykR9z9YJN9GWmUfjWy35oI/5CkmSN+vkbSzgb6MSp331l93SPpZxp+mzJIdp9ZJLX6uqfh/vyVu+9291PuflrSM2pw31UrSz8v6Yfu/kJ1c+P7brR+NbXfmgj/G5Lmmdl1ZnaRpK9KerGBfnyKmU2sPoiRmU2U9GUN3urDL0paWX2/UtL6BvvyCYOycnPdytJqeN8N2orXjZzkUw1lPC1pjKS17v7NvndiFGb2eQ2/2kvDVzz+qMm+mdmzkpZp+Kqv3ZK+Iem/Jf1U0rWS/ixphbv3/YO3mr4t0zmu3NyjvtWtLP26Gtx33Vzxuiv94Qw/ICfO8AOSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kNT/A6Ma+309/ECyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(images[21, 10], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 30, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 784)\n",
      "(450, 784)\n"
     ]
    }
   ],
   "source": [
    "train_features = images[:, :15].reshape(-1, (28 * 28))\n",
    "test_features = images[:, 15:30].reshape(-1, (28 * 28))\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "#ADDED FOR MEAN NORMALIZATION\n",
    "train_features -= np.mean(train_features, axis = 0)\n",
    "test_features -= np.mean(train_features, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, result, neighbors, dist = knn.findNearest(test_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the results are correct\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "#convert bool to int\n",
    "matches = matches.astype(np.int)\n",
    "\n",
    "#count the correct predictions\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "#compute the accuracy\n",
    "accuracy = (correct * 100.00) / result.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.0\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM MNIST (DIGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2000)\n"
     ]
    }
   ],
   "source": [
    "mnist = cv2.imread('../datasets/digits.png', 0)\n",
    "print(mnist.shape)\n",
    "images = [np.hsplit(row, 100) for row in np.vsplit(mnist, 50)]\n",
    "images = np.array(images, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 400)\n",
      "(2500, 400)\n"
     ]
    }
   ],
   "source": [
    "train_features = images[:, :50].reshape(-1, (20 * 20))\n",
    "test_features = images[:, 50:100].reshape(-1, (20 * 20))\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "#ADDED FOR MEAN NORMALIZATION\n",
    "train_features -= np.mean(train_features, axis = 0)\n",
    "test_features -= np.mean(train_features, axis = 0)\n",
    "\n",
    "knn = cv2.ml.KNearest_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.ml.SVM_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.8\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM FASHION MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 840)\n"
     ]
    }
   ],
   "source": [
    "fnist = cv2.imread('../datasets/fashion.png', 0)\n",
    "print(fnist.shape)\n",
    "images = [np.hsplit(row, 30) for row in np.vsplit(fnist, 30)]\n",
    "images = np.array(images, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 784)\n",
      "(450, 784)\n"
     ]
    }
   ],
   "source": [
    "train_features = images[:, :15].reshape(-1, (28 * 28))\n",
    "test_features = images[:, 15:30].reshape(-1, (28 * 28))\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "#ADDED FOR MEAN NORMALIZATION\n",
    "train_features -= np.mean(train_features, axis = 0)\n",
    "test_features -= np.mean(train_features, axis = 0)\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "ret, result, neighbors, dist = knn.findNearest(test_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cv2.ml.SVM_create()\n",
    "\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "\n",
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.44444444444444\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(test_features)\n",
    "\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2000)\n",
      "(2500, 400)\n",
      "(2500, 400)\n",
      "Accuracy: 91.64\n"
     ]
    }
   ],
   "source": [
    "#PCA MNIST\n",
    "mnist = cv2.imread('../datasets/digits.png', 0)\n",
    "print(mnist.shape)\n",
    "images = [np.hsplit(row, 100) for row in np.vsplit(mnist, 50)]\n",
    "images = np.array(images, dtype=np.float32)\n",
    "\n",
    "pca = PCA(n_components = images.shape[1])\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "train_features = images[:, :50].reshape(-1, (20 * 20))\n",
    "test_features = images[:, 50:100].reshape(-1, (20 * 20))\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "pca.fit(train_features)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "ret, result, neighbors, dist = knn.findNearest(test_features, 3)\n",
    "\n",
    "#check if the results are correct\n",
    "matches = np.equal(result, test_labels)\n",
    "#convert bool to int\n",
    "matches = matches.astype(np.int)\n",
    "#count the correct predictions\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "#compute the accuracy\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 784)\n",
      "(450, 784)\n",
      "Accuracy: 70.88888888888889\n"
     ]
    }
   ],
   "source": [
    "#PCA FASHION MNIST\n",
    "fnist = cv2.imread('../datasets/fashion.png', 0)\n",
    "images = [np.hsplit(row, 30) for row in np.vsplit(fnist, 30)]\n",
    "images = np.array(images, dtype=np.float32)\n",
    "\n",
    "pca = PCA(n_components = images.shape[1])\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "train_features = images[:, :15].reshape(-1, (28 * 28))\n",
    "test_features = images[:, 15:30].reshape(-1, (28 * 28))\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "pca.fit(train_features)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "ret, result, neighbors, dist = knn.findNearest(test_features, 3)\n",
    "\n",
    "#check if the results are correct\n",
    "matches = np.equal(result, test_labels)\n",
    "#convert bool to int\n",
    "matches = matches.astype(np.int)\n",
    "#count the correct predictions\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "#compute the accuracy\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
